import pandas as pd
from sqlalchemy import create_engine, Table, Column, MetaData
from sqlalchemy.dialects.mysql import LONGTEXT, VARCHAR, FLOAT
import pymysql
import argparse
import os
import sys

# Airflow ê²½ë¡œ
AIRFLOW_HOME = "/opt/airflow"

# AWS ë° DB í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_NAME = os.getenv("DB_NAME")
DB_PORT = int(os.getenv("DB_PORT", 3306))

AWS_ACCESS_KEY = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")

def summarize(text, limit=10000):
    if isinstance(text, str) and len(text) > limit:
        return text[:limit] + "...(ì´í•˜ ìƒëµ)"
    return text

def save_to_rds(filepath, table_name="news_posts"):
    print(f"ğŸ“‚ [DB ì €ì¥ ì‹œì‘] íŒŒì¼ ê²½ë¡œ: {filepath}")

    # 1. íŒŒì¼ ì½ê¸° (S3 ì§€ì›)
    storage_options = None
    
    # S3 ê²½ë¡œì¸ ê²½ìš°
    if filepath.startswith("s3://"):
        if not AWS_ACCESS_KEY or not AWS_SECRET_KEY:
            print("âŒ AWS ìê²© ì¦ëª…(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            sys.exit(1)
        storage_options = {"key": AWS_ACCESS_KEY, "secret": AWS_SECRET_KEY}
    
    # ë¡œì»¬ ê²½ë¡œì¸ ê²½ìš° ì ˆëŒ€ ê²½ë¡œ ë³€í™˜ ë° ì¡´ì¬ í™•ì¸
    else:
        if not os.path.isabs(filepath):
            filepath = os.path.join(AIRFLOW_HOME, filepath)
        if not os.path.exists(filepath):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
            sys.exit(1)

    try:
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì½ê¸° í•¨ìˆ˜ ë¶„ê¸°
        if filepath.endswith(".xlsx"):
            df = pd.read_excel(filepath, storage_options=storage_options)
        else:
            df = pd.read_csv(filepath, storage_options=storage_options) #
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(df)}í–‰")
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        sys.exit(1)

    # 2. ë°ì´í„° ì „ì²˜ë¦¬
    if "ê²Œì‹œë¬¼ ë‚´ìš©" in df.columns:
        df["ê²Œì‹œë¬¼ ë‚´ìš©"] = df["ê²Œì‹œë¬¼ ë‚´ìš©"].apply(summarize)

    # 3. RDS ì—°ê²°
    if not DB_HOST:
        print("âŒ DB ì—°ê²° ì •ë³´(DB_HOST)ê°€ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    db_url = f"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}?charset=utf8mb4"
    engine = create_engine(db_url)
    metadata = MetaData()

    # 4. í…Œì´ë¸” ì •ì˜
    news_posts_table = Table(
        table_name,
        metadata,
        Column("ê²€ìƒ‰ì–´", VARCHAR(100)),
        Column("í”Œë«í¼", VARCHAR(100)),
        Column("ê²Œì‹œë¬¼ URL", VARCHAR(500)),
        Column("ê²Œì‹œë¬¼ ì œëª©", VARCHAR(500)),
        Column("ê²Œì‹œë¬¼ ë‚´ìš©", LONGTEXT),
        Column("ê²Œì‹œë¬¼ ë“±ë¡ì¼ì", VARCHAR(50)),
        Column("ê³„ì •ëª…", VARCHAR(100)),
        Column("ìˆ˜ì§‘ì‹œê°„", VARCHAR(50)),
        Column("ì›ë³¸ê¸°ì‚¬", VARCHAR(500)),
        Column("ë³µì‚¬ìœ¨", FLOAT),
    )

    # 5. ì €ì¥ (ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ í›„ ì¬ìƒì„±)
    try:
        print(f"ğŸ”„ í…Œì´ë¸” '{table_name}' ì´ˆê¸°í™” ë° ì €ì¥ ì¤‘...")
        news_posts_table.drop(engine, checkfirst=True)
        news_posts_table.create(engine)
        
        df.to_sql(name=table_name, con=engine, if_exists="append", index=False)
        print("âœ… DB ì €ì¥ ì™„ë£Œ.")
    except Exception as e:
        print(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    # ì¸ì ì´ë¦„ì„ í†µì¼í–ˆìŠµë‹ˆë‹¤ (--input_file)
    parser.add_argument("--input_file", required=True, help="ì…ë ¥ íŒŒì¼ ê²½ë¡œ (ë¡œì»¬ ë˜ëŠ” S3)")
    parser.add_argument("--table_name", default="news_posts", help="í…Œì´ë¸” ì´ë¦„")

    args = parser.parse_args()
    save_to_rds(args.input_file, args.table_name)