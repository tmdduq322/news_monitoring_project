import argparse
import os
import sys
import pandas as pd
from extraction.main_script import find_original_article_multiprocess
from extraction.core_utils import log
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed
# from webdriver_manager.chrome import ChromeDriverManager # í•„ìš” ì‹œ ì£¼ì„ í•´ì œ

# Airflow ê²½ë¡œ ì„¤ì •
AIRFLOW_HOME = "/opt/airflow"

# AWS ì¸ì¦ ì •ë³´
AWS_ACCESS_KEY = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")

today = datetime.now().strftime("%y%m%d")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ì›ë¬¸ê¸°ì‚¬ ë§¤ì¹­ ë° ë³µì‚¬ìœ¨ ê³„ì‚°")
    parser.add_argument("--input_excel", required=True, help="ì „ì²˜ë¦¬ëœ ì…ë ¥ ì—‘ì…€ ê²½ë¡œ (ë¡œì»¬)")
    parser.add_argument("--output_csv", required=True, help="ê²°ê³¼ ì €ì¥ csv ê²½ë¡œ (ë¡œì»¬ ë˜ëŠ” S3)")

    args = parser.parse_args()

    # 1. ì…ë ¥ íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬ (ë¡œì»¬ íŒŒì¼)
    # ì…ë ¥ ê²½ë¡œê°€ ì ˆëŒ€ ê²½ë¡œê°€ ì•„ë‹ˆë¼ë©´ AIRFLOW_HOMEì„ ë¶™ì—¬ì¤Œ
    if not os.path.isabs(args.input_excel):
        input_path = os.path.join(AIRFLOW_HOME, args.input_excel)
    else:
        input_path = args.input_excel

    if not os.path.exists(input_path):
        log(f"âŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        sys.exit(1)

    log(f"ğŸ“‚ ì…ë ¥ íŒŒì¼ ì½ê¸°: {input_path}")
    try:
        df = pd.read_excel(input_path)
    except Exception as e:
        log(f"âŒ ì—‘ì…€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        sys.exit(1)

    total = len(df)
    log(f"ğŸ“„ ì „ì²´ ê²Œì‹œê¸€ ìˆ˜: {total}ê°œ")

    # URL í•˜ì´í¼ë§í¬ ì²˜ë¦¬
    if "ê²Œì‹œë¬¼ URL" in df.columns:
        df["ê²Œì‹œë¬¼ URL"] = df["ê²Œì‹œë¬¼ URL"].apply(
            lambda x: f'=HYPERLINK("{x}")' if pd.notna(x) and not str(x).startswith("=HYPERLINK") else x
        )
    
    df["ì›ë³¸ê¸°ì‚¬"] = ""
    df["ë³µì‚¬ìœ¨"] = 0.0

    # ë©€í‹°í”„ë¡œì„¸ì‹± ì‘ì—…
    tasks = [(i, row.to_dict(), total) for i, row in df.iterrows()]

    with ProcessPoolExecutor(max_workers=3) as executor:
        futures = [executor.submit(find_original_article_multiprocess, *args) for args in tasks]
        for future in as_completed(futures):
            try:
                index, link, score = future.result()
                df.at[index, "ì›ë³¸ê¸°ì‚¬"] = link
                df.at[index, "ë³µì‚¬ìœ¨"] = score
            except Exception as e:
                log(f"âŒ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    # ë§¤ì¹­ ê²°ê³¼ í†µê³„
    matched_count = df["ë³µì‚¬ìœ¨"].gt(0).sum()
    log(f"âœ¨ ë§¤ì¹­ ì™„ë£Œ: {matched_count}ê±´ ë§¤ì¹­ë¨")

    # 2. ê²°ê³¼ ì €ì¥ (S3 ë˜ëŠ” ë¡œì»¬)
    output_path = args.output_csv
    storage_options = None

    if output_path.startswith("s3://"):
        # S3 ì €ì¥ ì„¤ì •
        if not AWS_ACCESS_KEY or not AWS_SECRET_KEY:
            log("âŒ AWS ìê²© ì¦ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)
        storage_options = {
            "key": AWS_ACCESS_KEY,
            "secret": AWS_SECRET_KEY
        }
        log(f"â˜ï¸ S3 ì—…ë¡œë“œ ì‹œì‘: {output_path}")
    else:
        # ë¡œì»¬ ì €ì¥ ì„¤ì •
        if not os.path.isabs(output_path):
            output_path = os.path.join(AIRFLOW_HOME, output_path)
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        log(f"ğŸ’¾ ë¡œì»¬ ì €ì¥ ì‹œì‘: {output_path}")

    try:
        df.to_csv(output_path, index=False, encoding='utf-8-sig', storage_options=storage_options)
        log("âœ… ì €ì¥ ì™„ë£Œ.")
    except Exception as e:
        log(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        sys.exit(1)