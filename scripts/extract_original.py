import argparse
import os
import pandas as pd
from extraction.main_script import find_original_article_multiprocess
from extraction.core_utils import log
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed
from webdriver_manager.chrome import ChromeDriverManager

# [ì¤‘ìš”] Airflow ì»¨í…Œì´ë„ˆì˜ ê¸°ë³¸ í™ˆ ë””ë ‰í† ë¦¬ ê³ ì •
AIRFLOW_HOME = "/opt/airflow"

today = datetime.now().strftime("%y%m%d")

if __name__ == "__main__":
    #  ë“œë¼ì´ë²„ë¥¼ ë¯¸ë¦¬ í•œ ë²ˆ ì„¤ì¹˜í•˜ì—¬ ìºì‹œ ìƒì„±
    print("ğŸš— ChromeDriver ì„¤ì¹˜ í™•ì¸ ì¤‘...")
    ChromeDriverManager().install()
    parser = argparse.ArgumentParser(description="ì›ë¬¸ê¸°ì‚¬ ë§¤ì¹­ ë° ë³µì‚¬ìœ¨ ê³„ì‚°")
    parser = argparse.ArgumentParser(description="ì›ë¬¸ê¸°ì‚¬ ë§¤ì¹­ ë° ë³µì‚¬ìœ¨ ê³„ì‚°")
    parser.add_argument("--input_excel", required=True, help="ì „ì²˜ë¦¬ëœ ì…ë ¥ ì—‘ì…€ ê²½ë¡œ")
    parser.add_argument("--output_csv", required=True, help="ê²°ê³¼ ì €ì¥ csv ê²½ë¡œ")

    args = parser.parse_args()

    # [ìˆ˜ì •ëœ í•µì‹¬ ë¶€ë¶„]
    # ì…ë ¥ë°›ì€ ê²½ë¡œê°€ 'data/...' ê°™ì€ ìƒëŒ€ ê²½ë¡œë¼ë©´, ë¬´ì¡°ê±´ /opt/airflowë¥¼ ì•ì— ë¶™ì…ë‹ˆë‹¤.
    # ì´ë ‡ê²Œ í•˜ë©´ ì‹¤í–‰ ìœ„ì¹˜ê°€ /tmp ë“  ì–´ë””ë“  ìƒê´€ì—†ì´ ì •í™•í•œ íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
    
    if not os.path.isabs(args.input_excel):
        input_path = os.path.join(AIRFLOW_HOME, args.input_excel)
    else:
        input_path = args.input_excel

    if not os.path.isabs(args.output_csv):
        output_path = os.path.join(AIRFLOW_HOME, args.output_csv)
    else:
        output_path = args.output_csv

    log(f"ğŸ“‚ [Input] ì½ì„ íŒŒì¼: {input_path}")
    log(f"ğŸ“‚ [Output] ì €ì¥ ê²½ë¡œ: {output_path}")

    # ì €ì¥í•  í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    # ì—‘ì…€ ì½ê¸°
    try:
        df = pd.read_excel(input_path, dtype={"ê²Œì‹œê¸€ ë“±ë¡ì¼ì": str})
    except FileNotFoundError:
        log(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ í™•ì‹¤í•˜ê²Œ ì—ëŸ¬ë¥¼ ë‚´ê³  ì¢…ë£Œ
        exit(1)

    total = len(df)
    log(f"ğŸ“„ ì „ì²´ ê²Œì‹œê¸€ ìˆ˜: {total}ê°œ")

    if "ê²Œì‹œë¬¼ URL" in df.columns:
        df["ê²Œì‹œë¬¼ URL"] = df["ê²Œì‹œë¬¼ URL"].apply(
            lambda x: f'=HYPERLINK("{x}")' if pd.notna(x) and not str(x).startswith("=HYPERLINK") else x
        )
    
    df["ì›ë³¸ê¸°ì‚¬"] = ""
    df["ë³µì‚¬ìœ¨"] = 0.0

    # ë©€í‹°í”„ë¡œì„¸ì‹± ì‘ì—… ì¤€ë¹„
    tasks = [(i, row.to_dict(), total) for i, row in df.iterrows()]

    # [ì°¸ê³ ] core_utils.log ì„¤ì • ë•ë¶„ì— ì—¬ê¸°ì„œ ë°œìƒí•˜ëŠ” ë¡œê·¸ë„ /opt/airflow/data/log/extraction/log.txt ì— ìŒ“ì„
    with ProcessPoolExecutor(max_workers=3) as executor:
        futures = [executor.submit(find_original_article_multiprocess, *args) for args in tasks]
        for future in as_completed(futures):
            try:
                index, link, score = future.result()
                df.at[index, "ì›ë³¸ê¸°ì‚¬"] = link
                df.at[index, "ë³µì‚¬ìœ¨"] = score
            except Exception as e:
                log(f"âŒ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    # ë§¤ì¹­ í†µê³„ ê³„ì‚°
    matched_count = df["ë³µì‚¬ìœ¨"].gt(0).sum()
    above_80_count = df["ë³µì‚¬ìœ¨"].ge(0.8).sum()
    above_30_count = df["ë³µì‚¬ìœ¨"].ge(0.3).sum() - above_80_count

    stats_rows = pd.DataFrame([
        {"ê²€ìƒ‰ì–´": "ë§¤ì¹­ê±´ìˆ˜", "í”Œë«í¼": f"{matched_count}ê±´"},
        {"ê²€ìƒ‰ì–´": "0.3 ì´ìƒ", "í”Œë«í¼": f"{above_30_count}ê±´"},
        {"ê²€ìƒ‰ì–´": "0.8 ì´ìƒ", "í”Œë«í¼": f"{above_80_count}ê±´"},
    ])
    
    df = pd.concat([df, stats_rows], ignore_index=True)
    
    # CSV ì €ì¥
    df.to_csv(output_path, index=False, encoding='utf-8-sig') 
    log(f"ğŸ‰ ì‘ì—… ì™„ë£Œ! ìµœì¢… íŒŒì¼ ì €ì¥ë¨: {output_path}")