import argparse
import os
import sys
import pandas as pd
from extraction.main_script import find_original_article_multiprocess
from extraction.core_utils import log
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed

# 1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì ˆëŒ€ ê²½ë¡œ ì„¤ì • (í•˜ë“œì½”ë”©ëœ /opt/airflow ì œê±°)
SCRIPT_PATH = os.path.abspath(__file__)
PROJECT_ROOT_DIR = os.path.dirname(os.path.dirname(SCRIPT_PATH))

# AWS ì¸ì¦ ì •ë³´
AWS_ACCESS_KEY = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")

today = datetime.now().strftime("%y%m%d")

def resolve_path(path):
    """ì…ë ¥ëœ ê²½ë¡œê°€ ì ˆëŒ€ ê²½ë¡œë©´ ê·¸ëŒ€ë¡œ, ìƒëŒ€ ê²½ë¡œë©´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜"""
    if path.startswith("s3://"): # S3 ê²½ë¡œëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ
        return path
    if os.path.isabs(path):
        return path
    return os.path.join(PROJECT_ROOT_DIR, path)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ì›ë¬¸ê¸°ì‚¬ ë§¤ì¹­ ë° ë³µì‚¬ìœ¨ ê³„ì‚°")
    parser.add_argument("--input_excel", required=True, help="ì „ì²˜ë¦¬ëœ ì…ë ¥ ì—‘ì…€ ê²½ë¡œ")
    parser.add_argument("--output_csv", required=True, help="ê²°ê³¼ ì €ì¥ csv ê²½ë¡œ")

    args = parser.parse_args()

    # ê²½ë¡œ ë³€í™˜
    input_path = resolve_path(args.input_excel)

    if not os.path.exists(input_path):
        log(f"âŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        sys.exit(1)

    log(f"ğŸ“‚ ì…ë ¥ íŒŒì¼ ì½ê¸°: {input_path}")
    try:
        df = pd.read_excel(input_path)
    except Exception as e:
        log(f"âŒ ì—‘ì…€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        sys.exit(1)

    total = len(df)
    log(f"ğŸ“„ ì „ì²´ ê²Œì‹œê¸€ ìˆ˜: {total}ê°œ")

    # URL í•˜ì´í¼ë§í¬ ì²˜ë¦¬
    if "ê²Œì‹œë¬¼ URL" in df.columns:
        df["ê²Œì‹œë¬¼ URL"] = df["ê²Œì‹œë¬¼ URL"].apply(
            lambda x: f'=HYPERLINK("{x}")' if pd.notna(x) and not str(x).startswith("=HYPERLINK") else x
        )
    
    df["ì›ë³¸ê¸°ì‚¬"] = ""
    df["ë³µì‚¬ìœ¨"] = 0.0

    # ë©€í‹°í”„ë¡œì„¸ì‹± ì‘ì—…
    tasks = [(i, row.to_dict(), total) for i, row in df.iterrows()]
    
    # Worker ìˆ˜ ì¡°ì ˆ (ë„ˆë¬´ ë§ìœ¼ë©´ ë©”ëª¨ë¦¬ ë¶€ì¡± ê°€ëŠ¥ì„±)
    with ProcessPoolExecutor(max_workers=2) as executor:
        futures = [executor.submit(find_original_article_multiprocess, *args) for args in tasks]
        for future in as_completed(futures):
            try:
                index, link, score = future.result()
                df.at[index, "ì›ë³¸ê¸°ì‚¬"] = link
                df.at[index, "ë³µì‚¬ìœ¨"] = score
            except Exception as e:
                log(f"âŒ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    # ë§¤ì¹­ ê²°ê³¼ í†µê³„
    matched_count = df["ë³µì‚¬ìœ¨"].gt(0).sum()
    log(f"âœ¨ ë§¤ì¹­ ì™„ë£Œ: {matched_count}ê±´ ë§¤ì¹­ë¨")

    # 2. ê²°ê³¼ ì €ì¥ (S3 ë˜ëŠ” ë¡œì»¬)
    output_path = resolve_path(args.output_csv)
    storage_options = None

    if output_path.startswith("s3://"):
        if not AWS_ACCESS_KEY or not AWS_SECRET_KEY:
            log("âŒ AWS ìê²© ì¦ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)
        storage_options = {
            "key": AWS_ACCESS_KEY,
            "secret": AWS_SECRET_KEY
        }
        log(f"â˜ï¸ S3 ì—…ë¡œë“œ ì‹œì‘: {output_path}")
    else:
        # ë¡œì»¬ í´ë” ìƒì„±
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        log(f"ğŸ’¾ ë¡œì»¬ ì €ì¥ ì‹œì‘: {output_path}")

    try:
        df.to_csv(output_path, index=False, encoding='utf-8-sig', storage_options=storage_options)
        log("âœ… ì €ì¥ ì™„ë£Œ.")
    except Exception as e:
        log(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        sys.exit(1)