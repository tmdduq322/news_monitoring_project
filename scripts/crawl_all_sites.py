import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import pandas as pd
from datetime import datetime
from threading import Event
import argparse

# ê° í¬ë¡¤ëŸ¬ ëª¨ë“ˆ ì„í¬íŠ¸
from crawlers.pp_crawler import pp_main_crw
from crawlers.clien_crawler import clien_main_crw
from crawlers.inven_crawler import inven_main_crw
from crawlers.todayhumor_crawler import todayhumor_main_crw
from crawlers.paan_crawler import paan_main_crw
from crawlers.instiz_crawler import instiz_main_crw
from crawlers.bobaedream_crawler import bobaedream_main_crw
from crawlers.rw_crawler import rw_main_crw
from crawlers.arca_crawler import arca_main_crw
from crawlers.ilbe_crawler import ilbe_main_crw
from crawlers.humoruniv_crawler import humoruniv_main_crw
from crawlers.cook82_crawler import cook82_main_crw
from crawlers.orbi_crawler import orbi_main_crw
from crawlers.dogdrip_crawler import dogdrip_main_crw
from crawlers.dp_crawler import dp_main_crw
from crawlers.scline_crawler import scline_main_crw
from crawlers.dongsaroma_crawler import dongsaroma_main_crw
from crawlers.fomos_crawler import fomos_main_crw
from crawlers.jjang0u_crawler import jjang0u_main_crw
from crawlers.blind_crawler import blind_main_crw
from crawlers.mlb_crawler import mlb_main_crw
from crawlers.dc_crawler import dc_main_crw
from crawlers.fm_crawler import fm_main_crw
from crawlers.dq_crawler import dq_main_crw

# ì „ì—­ ì¤‘ë‹¨ í”Œë˜ê·¸
stop_event = Event()

# ì‚¬ì´íŠ¸ë³„ í•¨ìˆ˜ ë§¤í•‘
crawlers = {
    "ë½ë¿Œ": pp_main_crw,
    "í´ë¦¬ì•™": clien_main_crw,
    "ì¸ë²¤": inven_main_crw,
    "ë£¨ë¦¬ì›¹": rw_main_crw,
    "ì˜¤ëŠ˜ì˜ìœ ë¨¸": todayhumor_main_crw,
    "ë„¤ì´íŠ¸íŒ": paan_main_crw,
    "ì¸ìŠ¤í‹°ì¦ˆ": instiz_main_crw,
    "ë³´ë°°ë“œë¦¼": bobaedream_main_crw,
    "ì•„ì¹´ë¼ì´ë¸Œ": arca_main_crw,
    "ì¼ê°„ë² ìŠ¤íŠ¸": ilbe_main_crw,
    "ì›ƒê¸´ëŒ€í•™": humoruniv_main_crw,
    "82ì¿¡": cook82_main_crw,
    "ì˜¤ë¥´ë¹„": orbi_main_crw,
    "ê°œë“œë¦½": dogdrip_main_crw,
    "DVDí”„ë¼ì„": dp_main_crw,
    "ì‚¬ì»¤ë¼ì¸": scline_main_crw,
    "ë™ì‚¬ë¡œë§ˆë‹·ì»´": dongsaroma_main_crw,
    "í¬ëª¨ìŠ¤": fomos_main_crw,
    "ì§±ê³µìœ ë‹·ì»´": jjang0u_main_crw,
    "ë¸”ë¼ì¸ë“œ": blind_main_crw,
    "ì— ì—˜ë¹„íŒŒí¬": mlb_main_crw,
    "ë””ì‹œì¸ì‚¬ì´ë“œ": dc_main_crw,
    "ì—í¨ì½”ë¦¬ì•„": fm_main_crw,
    "ë”ì¿ ": dq_main_crw
}

def main(site, start_date, end_date, search_excel):
    # 1. ì—‘ì…€ ë° ë‚ ì§œ ë¡œë“œ
    pd_search = pd.read_excel(search_excel, sheet_name='ê²€ìƒ‰ì–´ ëª©ë¡')
    searchs = pd_search['ê²€ìƒ‰ì–´ëª…']
    start_date_obj = datetime.strptime(start_date, "%Y-%m-%d").date()
    end_date_obj = datetime.strptime(end_date, "%Y-%m-%d").date()

    # 2. "all" ì…ë ¥ ì‹œ ì „ì²´ í¬ë¡¤ëŸ¬ ìˆœì°¨ ì‹¤í–‰ 
    if site == "all":
        print(f"ğŸ“¢ [ì „ì²´ ëª¨ë“œ] ì´ {len(crawlers)}ê°œ ì‚¬ì´íŠ¸ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        for site_name, crawler_func in crawlers.items():
            print(f"\nğŸš€ [{site_name}] í¬ë¡¤ë§ ì‹œì‘...")
            try:
                # ê° í¬ë¡¤ëŸ¬ ì‹¤í–‰
                crawler_func(searchs, start_date_obj, end_date_obj, stop_event)
                print(f"âœ… [{site_name}] ì™„ë£Œ")
            except Exception as e:
                # í•˜ë‚˜ê°€ ì‹¤íŒ¨í•´ë„ ë‚˜ë¨¸ì§€ëŠ” ê³„ì† ì§„í–‰í•˜ë„ë¡ ì˜ˆì™¸ ì²˜ë¦¬
                print(f"âŒ [{site_name}] í¬ë¡¤ë§ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
                
        print("\nğŸ‰ ëª¨ë“  ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì‘ì—… ì¢…ë£Œ")

    # 3. íŠ¹ì • ì‚¬ì´íŠ¸ ì…ë ¥ ì‹œ í•´ë‹¹ í¬ë¡¤ëŸ¬ë§Œ ì‹¤í–‰
    elif site in crawlers:
        print(f"ğŸš€ [{site}] í¬ë¡¤ë§ ì‹œì‘...")
        crawlers[site](searchs, start_date_obj, end_date_obj, stop_event)
        print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ")

    # 4. ì˜ëª»ëœ ì…ë ¥ ì²˜ë¦¬
    else:
        print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤: {site}")
        print(f"   (ì‚¬ìš© ê°€ëŠ¥: 'all' ë˜ëŠ” {', '.join(crawlers.keys())})")
        return

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ì‚¬ì´íŠ¸ë³„ ì»¤ë®¤ë‹ˆí‹° í¬ë¡¤ëŸ¬ ì‹¤í–‰")
    parser.add_argument("--site", required=True, help="ì‚¬ì´íŠ¸ ì´ë¦„ (ì˜ˆ: ë£¨ë¦¬ì›¹, ë³´ë°°ë“œë¦¼, all)")
    parser.add_argument("--start_date", required=True, help="ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)")
    parser.add_argument("--end_date", required=True, help="ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)")
    parser.add_argument("--search_excel", required=True, help="ê²€ìƒ‰ì–´ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ")

    args = parser.parse_args()
    main(args.site, args.start_date, args.end_date, args.search_excel)