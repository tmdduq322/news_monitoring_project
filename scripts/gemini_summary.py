import os
import sys
import time
import re
import pymysql
import requests
import argparse
import google.generativeai as genai
from datetime import datetime

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
keys_env = os.getenv("GEMINI_API_KEYS")
if not keys_env:
    keys_env = os.getenv("GEMINI_API_KEY")

API_KEYS = keys_env.split(',') if keys_env else []
current_key_index = 0

NOTION_TOKEN = os.getenv("NOTION_TOKEN")
NOTION_PAGE_ID = os.getenv("NOTION_PAGE_ID") 
DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_NAME = os.getenv("DB_NAME")

# ë¡œê·¸ ì¶œë ¥ í•¨ìˆ˜
def log(message):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {message}", flush=True)

if not API_KEYS:
    log("âŒ GEMINI_API_KEYSê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

if not NOTION_PAGE_ID:
    log("âŒ NOTION_PAGE_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# ì´ˆê¸° ì„¤ì •
def configure_genai(key_index):
    global model
    try:
        current_key = API_KEYS[key_index].strip()
        genai.configure(api_key=current_key)
        model = genai.GenerativeModel('gemini-2.5-flash')
        log(f"ğŸ”‘ API Key #{key_index + 1} ì ìš© ì™„ë£Œ (ì´ {len(API_KEYS)}ê°œ)")
    except Exception as e:
        log(f"âŒ API Key ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
        sys.exit(1)

configure_genai(current_key_index)

def get_yesterday_data(target_date):
    """DBì—ì„œ í•´ë‹¹ ë‚ ì§œì˜ ì£¼ìš” ê¸°ì‚¬ ì œëª© + URL ì¶”ì¶œ"""
    conn = pymysql.connect(host=DB_HOST, user=DB_USER, password=DB_PASSWORD, db=DB_NAME, charset='utf8mb4')
    try:
        with conn.cursor() as cursor:
            sql = f"""
                SELECT keyword, title, original_article_url
                FROM news_posts 
                WHERE DATE(crawled_at) = '{target_date}'
                ORDER BY copy_rate DESC LIMIT 100
            """
            cursor.execute(sql)
            results = cursor.fetchall()
            
            formatted_data = []
            for row in results:
                keyword = row[0]
                title = row[1]
                url = row[2] if row[2] else "URL ì—†ìŒ"
                formatted_data.append(f"- [{keyword}] {title} (URL: {url})")
            return formatted_data
    except Exception as e:
        log(f"âŒ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
        sys.exit(1)
    finally:
        conn.close()

def generate_summary(data_list):
    """ì œë¯¸ë‚˜ì´ë¥¼ ì´ìš©í•œ íŠ¸ë Œë“œ ìš”ì•½ ìƒì„±"""
    global current_key_index
    if not data_list:
        return "ë°ì´í„°ê°€ ì—†ì–´ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    context = "\n".join(data_list)
    
    # [í”„ë¡¬í”„íŠ¸ ìˆ˜ì •] 5ê°€ì§€ ì´ìŠˆ/URL ìš”ì²­ ë° ì •ì¹˜/ì•ˆë³´ ì´ìŠˆ ë³¼ë“œ ì²˜ë¦¬ ì§€ì‹œ
    prompt = f"""
    ë„ˆëŠ” ë‰´ìŠ¤ ë°ì´í„° ë¶„ì„ê°€ì•¼. ì•„ë˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŠ¸ë Œë“œë¥¼ ìš”ì•½í•´ì¤˜.
    
    [ë°ì´í„°]
    {context}

    [í˜•ì‹]
    ğŸ’¡ ì˜¤ëŠ˜ì˜ í•µì‹¬ ì´ìŠˆ (5ê°€ì§€)
    1. (ì´ìŠˆ 1 - 2ì¤„ ìš”ì•½)
    2. (ì´ìŠˆ 2)
    3. (ì´ìŠˆ 3)
    4. (ì´ìŠˆ 4)
    5. (ì´ìŠˆ 5)

    ğŸ”¥ íŠ¸ë Œë“œ ë¶„ì„
    (ê´€ì‹¬ì‚¬ ë¶„ì„ 3ë¬¸ì¥)

    ğŸ“° ì£¼ìš” ë‰´ìŠ¤ ë°”ë¡œê°€ê¸° (5ê°œ ì¶”ì²œ)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)

    [ì£¼ì˜ì‚¬í•­]
    1. ì´ìŠˆ ë¶€ë¶„ì˜ ì œëª©ì€ **êµµê²Œ** í‘œì‹œí•´ì„œ ê°•ì¡°í•´ì¤˜. (ì˜ˆ: **ì—¬ì•¼ ê°ˆë“± ì‹¬í™”**)
    2. ë§í¬ëŠ” ë°˜ë“œì‹œ [ì œëª©](ì£¼ì†Œ) í˜•ì‹ì„ ì§€í‚¬ ê²ƒ.
    3. ê·¸ ì™¸ ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´ í—¤ë”(## ë“±)ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆ.
    """
    
    max_retries = 3
    attempt = 0
    
    while attempt < max_retries:
        try:
            log(f"ğŸ¤– Gemini ìš”ì²­ ì‹œì‘ (Key #{current_key_index + 1}, ì‹œë„ {attempt + 1})...")
            response = model.generate_content(prompt)
            # **(ë³¼ë“œ)ëŠ” ì‚´ë¦¬ê³ , ##(í—¤ë”)ë§Œ ì œê±°
            text = response.text.replace("##", "").replace("###", "")
            return text
            
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "Quota" in error_msg or "ResourceExhausted" in error_msg:
                log(f"âš ï¸ í˜„ì¬ í‚¤(#{current_key_index + 1}) í•œë„ ì´ˆê³¼!")
                if len(API_KEYS) > 1:
                    current_key_index = (current_key_index + 1) % len(API_KEYS)
                    log(f"â™»ï¸ ë‹¤ìŒ í‚¤(#{current_key_index + 1})ë¡œ êµì²´í•©ë‹ˆë‹¤...")
                    configure_genai(current_key_index)
                    time.sleep(2)
                    continue 
                else:
                    wait_time = 60
                    log(f"â³ ì˜ˆë¹„ í‚¤ ì—†ìŒ. {wait_time}ì´ˆ ëŒ€ê¸°...")
                    time.sleep(wait_time)
                    attempt += 1
            else:
                log(f"âš ï¸ ì˜¤ë¥˜: {error_msg}")
                time.sleep(10)
                attempt += 1
            
    log("âŒ ì‹¤íŒ¨: ëª¨ë“  ì¬ì‹œë„ ì†Œì§„.")
    sys.exit(1)

# ğŸ‘‡ [í•µì‹¬ ê¸°ëŠ¥ ê°•í™”] ë³¼ë“œ(**)ì™€ í•˜ì´í¼ë§í¬([]) ë™ì‹œ íŒŒì‹± ë¡œì§
def parse_markdown_to_notion_blocks(text):
    blocks = []
    lines = text.split('\n')
    
    # 1. í†µí•© íŒ¨í„´: (**ë³¼ë“œ**) ë˜ëŠ” ([ë§í¬](ì£¼ì†Œ))
    # ìˆœì„œ: ë³¼ë“œ ë¨¼ì € ì²´í¬í•˜ê³ , ê·¸ ë‹¤ìŒ ë§í¬ ì²´í¬
    pattern = re.compile(r'(\*\*(?P<bold>.*?)\*\*)|(\[(?P<link_text>.*?)\]\s*\((?P<link_url>https?://.*?)\))')
    
    # 2. ë°±ì—…ìš© ë§í¬ íŒ¨í„´ (í˜•ì‹ì´ ê¹¨ì§„ ê²½ìš°: ì œëª© (ì£¼ì†Œ))
    fallback_link_pattern = re.compile(r'(.*)\s*\((https?://.*?)\)')

    for line in lines:
        line = line.strip()
        if not line: continue
        
        # ë¸”ë¡ íƒ€ì… ê²°ì •
        if line.startswith("- "):
            block_type = "bulleted_list_item"
            content = line[2:]
        elif line[0].isdigit() and line[1:3] == ". ":
            block_type = "numbered_list_item"
            content = line[3:]
        elif line.startswith("ğŸ’¡") or line.startswith("ğŸ”¥") or line.startswith("ğŸ“°"):
            block_type = "heading_3"
            content = line
        else:
            block_type = "paragraph"
            content = line

        rich_text = []
        last_idx = 0
        
        # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë³¼ë“œì™€ ë§í¬ ì°¾ê¸°
        matches = list(pattern.finditer(content))
        
        # ë§¤ì¹­ëœ ê²Œ í•˜ë‚˜ë„ ì—†ëŠ”ë° URLì´ í¬í•¨ëœ ê²½ìš° -> ë°±ì—… íŒ¨í„´ ì‹œë„
        if not matches and "http" in content:
            fallback_match = fallback_link_pattern.search(content)
            if fallback_match:
                # ë°±ì—… íŒ¨í„´ì€ ë‹¨ìˆœ í…ìŠ¤íŠ¸ + ë§í¬ë¡œ ì²˜ë¦¬
                pre_text = fallback_match.group(1).strip()
                url = fallback_match.group(2).strip()
                if pre_text:
                    rich_text.append({"type": "text", "text": {"content": pre_text + " "}})
                rich_text.append({
                    "type": "text", 
                    "text": {"content": pre_text if not pre_text else "ë§í¬", "link": {"url": url}}
                })
                # ì²˜ë¦¬ ì™„ë£Œë¡œ ê°„ì£¼
                matches = [] 
                last_idx = len(content) 

        for match in matches:
            # ë§¤ì¹­ ì•ë¶€ë¶„ ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ê°€
            if match.start() > last_idx:
                rich_text.append({"type": "text", "text": {"content": content[last_idx:match.start()]}})
            
            if match.group('bold'): # **ë³¼ë“œ** ë§¤ì¹­
                rich_text.append({
                    "type": "text",
                    "text": {"content": match.group('bold')},
                    "annotations": {"bold": True} # âœ¨ ë…¸ì…˜ ë³¼ë“œ ì ìš©
                })
            elif match.group('link_url'): # [ë§í¬](ì£¼ì†Œ) ë§¤ì¹­
                rich_text.append({
                    "type": "text",
                    "text": {
                        "content": match.group('link_text'),
                        "link": {"url": match.group('link_url')} # ğŸ”— ë…¸ì…˜ ë§í¬ ì ìš©
                    }
                })
            
            last_idx = match.end()
        
        # ë‚¨ì€ ë’·ë¶€ë¶„ í…ìŠ¤íŠ¸ ì¶”ê°€
        if last_idx < len(content):
            rich_text.append({"type": "text", "text": {"content": content[last_idx:]}})
            
        # rich_textê°€ ë¹„ì—ˆìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ (ì•ˆì „ì¥ì¹˜)
        if not rich_text:
            rich_text.append({"type": "text", "text": {"content": content}})

        blocks.append({
            "object": "block",
            "type": block_type,
            block_type: {
                "rich_text": rich_text
            }
        })
        
    return blocks

def create_summary_page_in_notion(summary_text, target_date):
    headers = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }
    
    # íŒŒì‹±ëœ ë¸”ë¡ ìƒì„±
    content_blocks = parse_markdown_to_notion_blocks(summary_text)

    payload = {
        "parent": {"page_id": NOTION_PAGE_ID}, 
        "properties": {
            "title": { 
                "title": [
                    {"text": {"content": f"ğŸ“° {target_date} ì–´ì œì˜ ì´ìŠˆ"}}
                ]
            }
        },
        "children": [
            {
                "object": "block",
                "type": "callout",
                "callout": {
                    "rich_text": [{"type": "text", "text": {"content": "Gemini  ë‰´ìŠ¤ ìš”ì•½"}}],
                    "icon": {"emoji": "ğŸ¤–"},
                    "color": "gray_background"
                }
            },
            {
                "object": "block",
                "type": "divider",
                "divider": {}
            }
        ] + content_blocks
    }
    
    url = "https://api.notion.com/v1/pages"
    
    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        log(f"âœ… ë…¸ì…˜ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {target_date}")
        
    except requests.exceptions.HTTPError as err:
        log(f"âŒ ë…¸ì…˜ ìš”ì²­ ì‹¤íŒ¨: {err}")
        log(f"ì‘ë‹µ ë‚´ìš©: {response.text}")
        sys.exit(1)

def run_gemini_pipeline(target_date):
    news_data = get_yesterday_data(target_date)
    log(f"ë°ì´í„° {len(news_data)}ê±´ ì¡°íšŒë¨.")
    
    if not news_data:
        log("ë°ì´í„°ê°€ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    summary = generate_summary(news_data)
    log("Gemini ìš”ì•½ ì™„ë£Œ.")
    
    create_summary_page_in_notion(summary, target_date)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--date", help="ë°ì´í„° ì¡°íšŒ ëŒ€ìƒ ë‚ ì§œ (YYYY-MM-DD)")
    args = parser.parse_args()

    if args.date:
        run_gemini_pipeline(args.date)
    else:
        log("âš ï¸ ë‚ ì§œ(--date) íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        sys.exit(1)