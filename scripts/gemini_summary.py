import os
import sys
import time
import re
import pymysql
import requests
import argparse
import google.generativeai as genai
from datetime import datetime

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
keys_env = os.getenv("GEMINI_API_KEYS")
if not keys_env:
    keys_env = os.getenv("GEMINI_API_KEY")

API_KEYS = keys_env.split(',') if keys_env else []
current_key_index = 0

NOTION_TOKEN = os.getenv("NOTION_TOKEN")
NOTION_PAGE_ID = os.getenv("NOTION_PAGE_ID") 
DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_NAME = os.getenv("DB_NAME")

# ë¡œê·¸ ì¶œë ¥ í•¨ìˆ˜
def log(message):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {message}", flush=True)

if not API_KEYS:
    log("âŒ GEMINI_API_KEYSê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

if not NOTION_PAGE_ID:
    log("âŒ NOTION_PAGE_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# ì´ˆê¸° ì„¤ì •
def configure_genai(key_index):
    global model
    try:
        current_key = API_KEYS[key_index].strip()
        genai.configure(api_key=current_key)
        model = genai.GenerativeModel('gemini-2.5-flash')
        log(f"ğŸ”‘ API Key #{key_index + 1} ì ìš© ì™„ë£Œ (ì´ {len(API_KEYS)}ê°œ)")
    except Exception as e:
        log(f"âŒ API Key ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
        sys.exit(1)

configure_genai(current_key_index)

def get_yesterday_data(target_date):
    """DBì—ì„œ í•´ë‹¹ ë‚ ì§œì˜ ì£¼ìš” ê¸°ì‚¬ ì œëª© + URL ì¶”ì¶œ"""
    conn = pymysql.connect(host=DB_HOST, user=DB_USER, password=DB_PASSWORD, db=DB_NAME, charset='utf8mb4')
    try:
        with conn.cursor() as cursor:
            # ì•ˆì „ì¥ì¹˜: LIMIT 200ìœ¼ë¡œ ì œí•œ
            sql = f"""
                SELECT keyword, title, original_article_url
                FROM news_posts 
                WHERE DATE(crawled_at) = '{target_date}' 
                AND copy_rate > 0.3
                ORDER BY copy_rate DESC 
                LIMIT 200
            """
            cursor.execute(sql)
            results = cursor.fetchall()
            
            formatted_data = []
            for row in results:
                keyword = row[0]
                title = row[1]
                url = row[2] if row[2] else "URL ì—†ìŒ"
                formatted_data.append(f"- [{keyword}] {title} (URL: {url})")
            return formatted_data
    except Exception as e:
        log(f"âŒ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
        sys.exit(1)
    finally:
        conn.close()

def generate_summary(data_list):
    """ì œë¯¸ë‚˜ì´ë¥¼ ì´ìš©í•œ íŠ¸ë Œë“œ ìš”ì•½ ìƒì„±"""
    global current_key_index
    if not data_list:
        return "ë°ì´í„°ê°€ ì—†ì–´ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    context = "\n".join(data_list)
    
    prompt = f"""
    ë„ˆëŠ” ë‰´ìŠ¤ ë°ì´í„° ë¶„ì„ê°€ì•¼. ì•„ë˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŠ¸ë Œë“œë¥¼ ìš”ì•½í•´ì¤˜.
    
    [ë°ì´í„°]
    {context}

    [í˜•ì‹]
    ğŸ’¡ ì˜¤ëŠ˜ì˜ í•µì‹¬ ì´ìŠˆ (5ê°€ì§€)
    1. (ì´ìŠˆ 1 - 2ì¤„ ìš”ì•½)
    2. (ì´ìŠˆ 2)
    3. (ì´ìŠˆ 3)
    4. (ì´ìŠˆ 4)
    5. (ì´ìŠˆ 5)

    ğŸ”¥ íŠ¸ë Œë“œ ë¶„ì„
    (ê´€ì‹¬ì‚¬ ë¶„ì„ 3ë¬¸ì¥)

    ğŸ“° ì£¼ìš” ë‰´ìŠ¤ ë°”ë¡œê°€ê¸° (5ê°œ ì¶”ì²œ)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)

    [ì£¼ì˜ì‚¬í•­]
    1. ê° ì´ìŠˆì˜ **í•µì‹¬ ì£¼ì œë‚˜ í‚¤ì›Œë“œ**ëŠ” ë¬¸ì¥ ì•ë¶€ë¶„ì— **êµµê²Œ** í‘œì‹œí•´ì„œ ê°•ì¡°í•´ì¤˜. (ì˜ˆ: **í•µì‹¬ ì£¼ì œ** ë‚´ìš© ì„¤ëª…...)
    2. ë§í¬ëŠ” ë°˜ë“œì‹œ [ì œëª©](ì£¼ì†Œ) í˜•ì‹ì„ ì§€í‚¬ ê²ƒ.
    3. ê·¸ ì™¸ ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´ í—¤ë”(## ë“±)ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆ.
    """
    
    max_retries = 3
    attempt = 0
    
    while attempt < max_retries:
        try:
            log(f"ğŸ¤– Gemini ìš”ì²­ ì‹œì‘ (Key #{current_key_index + 1}, ì‹œë„ {attempt + 1})...")
            response = model.generate_content(prompt)
            text = response.text.replace("##", "").replace("###", "")
            return text
            
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "Quota" in error_msg or "ResourceExhausted" in error_msg:
                log(f"âš ï¸ í˜„ì¬ í‚¤(#{current_key_index + 1}) í•œë„ ì´ˆê³¼!")
                if len(API_KEYS) > 1:
                    current_key_index = (current_key_index + 1) % len(API_KEYS)
                    log(f"â™»ï¸ ë‹¤ìŒ í‚¤(#{current_key_index + 1})ë¡œ êµì²´í•©ë‹ˆë‹¤...")
                    configure_genai(current_key_index)
                    time.sleep(2)
                    continue 
                else:
                    wait_time = 60
                    log(f"â³ ì˜ˆë¹„ í‚¤ ì—†ìŒ. {wait_time}ì´ˆ ëŒ€ê¸°...")
                    time.sleep(wait_time)
                    attempt += 1
            else:
                log(f"âš ï¸ ì˜¤ë¥˜: {error_msg}")
                time.sleep(10)
                attempt += 1
            
    log("âŒ ì‹¤íŒ¨: ëª¨ë“  ì¬ì‹œë„ ì†Œì§„.")
    sys.exit(1)

def parse_markdown_to_notion_blocks(text):
    """
    í…ìŠ¤íŠ¸ë¥¼ ë…¸ì…˜ ë¸”ë¡ìœ¼ë¡œ ë³€í™˜ (ë””ìì¸ ê°•í™” ë²„ì „)
    - êµ¬ë¶„ì„  ì¶”ê°€
    - í—¤ë” í¬ê¸° í™•ëŒ€ (H3 -> H2)
    - íŠ¸ë Œë“œ ë¶„ì„ì€ 'ì¸ìš©êµ¬(Quote)' ë¸”ë¡ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê°•ì¡°
    """
    blocks = []
    lines = text.split('\n')
    
    # ì •ê·œì‹ íŒ¨í„´ (ë³¼ë“œ & ë§í¬)
    pattern = re.compile(r'(\*\*(?P<bold>.*?)\*\*)|(\[(?P<link_text>.*?)\]\s*\((?P<link_url>https?://.*?)\))')
    fallback_link_pattern = re.compile(r'(.*)\s*\((https?://.*?)\)')

    # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì„¹ì…˜ ì¶”ì ìš© (trend, normal)
    current_section = "normal" 

    for line in lines:
        line = line.strip()
        if not line: continue
        
        # 1. ë¸”ë¡ íƒ€ì… ë° ë””ìì¸ ê²°ì •
        if line.startswith("- "):
            block_type = "bulleted_list_item"
            content = line[2:]
        elif line[0].isdigit() and line[1:3] == ". ":
            block_type = "numbered_list_item"
            content = line[3:]
        elif line.startswith("ğŸ’¡") or line.startswith("ğŸ”¥") or line.startswith("ğŸ“°"):
            # âœ¨ [ë””ìì¸] ì„¹ì…˜ì´ ë°”ë€” ë•Œë§ˆë‹¤ ìœ„ì— êµ¬ë¶„ì„  ì¶”ê°€ (ë§¨ ì²˜ìŒ ì œì™¸)
            if blocks: 
                blocks.append({"object": "block", "type": "divider", "divider": {}})
            
            block_type = "heading_2" # âœ¨ [ë””ìì¸] ì œëª©ì„ H2ë¡œ í‚¤ì›€
            content = line
            
            # ì„¹ì…˜ ìƒíƒœ ë³€ê²½
            if line.startswith("ğŸ”¥"):
                current_section = "trend"
            else:
                current_section = "normal"
        else:
            # âœ¨ [ë””ìì¸] íŠ¸ë Œë“œ ë¶„ì„ ì„¹ì…˜ì˜ ë³¸ë¬¸ì€ 'ì¸ìš©êµ¬'ë¡œ ì²˜ë¦¬í•´ ìˆì–´ ë³´ì´ê²Œ í•¨
            if current_section == "trend":
                block_type = "quote"
            else:
                block_type = "paragraph"
            content = line

        # 2. Rich Text íŒŒì‹± (ë³¼ë“œ, ë§í¬ ì ìš©)
        rich_text = []
        last_idx = 0
        
        matches = list(pattern.finditer(content))
        
        if not matches and "http" in content:
            fallback_match = fallback_link_pattern.search(content)
            if fallback_match:
                pre_text = fallback_match.group(1).strip()
                url = fallback_match.group(2).strip()
                if pre_text:
                    rich_text.append({"type": "text", "text": {"content": pre_text + " "}})
                rich_text.append({
                    "type": "text", 
                    "text": {"content": pre_text if not pre_text else "ë§í¬", "link": {"url": url}}
                })
                matches = [] 
                last_idx = len(content) 

        for match in matches:
            if match.start() > last_idx:
                rich_text.append({"type": "text", "text": {"content": content[last_idx:match.start()]}})
            
            if match.group('bold'):
                rich_text.append({
                    "type": "text",
                    "text": {"content": match.group('bold')},
                    "annotations": {"bold": True} # ë³¼ë“œ
                })
            elif match.group('link_url'):
                rich_text.append({
                    "type": "text",
                    "text": {
                        "content": match.group('link_text'),
                        "link": {"url": match.group('link_url')} # ë§í¬
                    }
                })
            
            last_idx = match.end()
        
        if last_idx < len(content):
            rich_text.append({"type": "text", "text": {"content": content[last_idx:]}})
            
        if not rich_text:
            rich_text.append({"type": "text", "text": {"content": content}})

        # 3. ë¸”ë¡ ìƒì„±
        blocks.append({
            "object": "block",
            "type": block_type,
            block_type: {
                "rich_text": rich_text,
                # í—¤ë”©ì˜ ê²½ìš° ìƒ‰ìƒì„ ì…í ìˆ˜ë„ ìˆìŒ (ì›í•˜ë©´ ì£¼ì„ í•´ì œ)
                # "color": "blue_background" if block_type == "heading_2" else "default"
            }
        })
        
    return blocks

def create_summary_page_in_notion(summary_text, target_date):
    headers = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }
    
    content_blocks = parse_markdown_to_notion_blocks(summary_text)

    payload = {
        "parent": {"page_id": NOTION_PAGE_ID}, 
        "properties": {
            "title": { 
                "title": [
                    {"text": {"content": f"ğŸ“° {target_date} ì–´ì œì˜ ì´ìŠˆ"}}
                ]
            }
        },
        "children": [
            {
                "object": "block",
                "type": "callout",
                "callout": {
                    "rich_text": [{"type": "text", "text": {"content": "Gemini ë‰´ìŠ¤ ìš”ì•½"}}],
                    "icon": {"emoji": "ğŸ¤–"},
                    "color": "gray_background"
                }
            },
            # ì²« ë²ˆì§¸ êµ¬ë¶„ì„ ì€ ì—¬ê¸°ì„œ ì œê±° (í•¨ìˆ˜ ì•ˆì—ì„œ ìë™ ì²˜ë¦¬ë¨)
        ] + content_blocks
    }
    
    url = "https://api.notion.com/v1/pages"
    
    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        log(f"âœ… ë…¸ì…˜ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {target_date}")
        
    except requests.exceptions.HTTPError as err:
        log(f"âŒ ë…¸ì…˜ ìš”ì²­ ì‹¤íŒ¨: {err}")
        log(f"ì‘ë‹µ ë‚´ìš©: {response.text}")
        sys.exit(1)

def run_gemini_pipeline(target_date):
    news_data = get_yesterday_data(target_date)
    log(f"ë°ì´í„° {len(news_data)}ê±´ ì¡°íšŒë¨.")
    
    if not news_data:
        log("ë°ì´í„°ê°€ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    summary = generate_summary(news_data)
    log("Gemini ìš”ì•½ ì™„ë£Œ.")
    
    create_summary_page_in_notion(summary, target_date)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--date", help="ë°ì´í„° ì¡°íšŒ ëŒ€ìƒ ë‚ ì§œ (YYYY-MM-DD)")
    args = parser.parse_args()

    if args.date:
        run_gemini_pipeline(args.date)
    else:
        log("âš ï¸ ë‚ ì§œ(--date) íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        sys.exit(1)