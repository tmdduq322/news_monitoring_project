import os
import sys
import time
import re
import pymysql
import requests
import argparse
import google.generativeai as genai
from datetime import datetime

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
keys_env = os.getenv("GEMINI_API_KEYS")
if not keys_env:
    keys_env = os.getenv("GEMINI_API_KEY")

API_KEYS = keys_env.split(',') if keys_env else []
current_key_index = 0

NOTION_TOKEN = os.getenv("NOTION_TOKEN")
NOTION_PAGE_ID = os.getenv("NOTION_PAGE_ID") 
DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_NAME = os.getenv("DB_NAME")

# ë¡œê·¸ ì¶œë ¥ í•¨ìˆ˜
def log(message):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {message}", flush=True)

if not API_KEYS:
    log("âŒ GEMINI_API_KEYSê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

if not NOTION_PAGE_ID:
    log("âŒ NOTION_PAGE_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# ì´ˆê¸° ì„¤ì •
def configure_genai(key_index):
    global model
    try:
        current_key = API_KEYS[key_index].strip()
        genai.configure(api_key=current_key)
        model = genai.GenerativeModel('gemini-2.5-flash')
        log(f"ğŸ”‘ API Key #{key_index + 1} ì ìš© ì™„ë£Œ (ì´ {len(API_KEYS)}ê°œ)")
    except Exception as e:
        log(f"âŒ API Key ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
        sys.exit(1)

configure_genai(current_key_index)

def get_yesterday_data(target_date):
    """DBì—ì„œ í•´ë‹¹ ë‚ ì§œì˜ ì£¼ìš” ê¸°ì‚¬ ì œëª© + URL ì¶”ì¶œ"""
    conn = pymysql.connect(host=DB_HOST, user=DB_USER, password=DB_PASSWORD, db=DB_NAME, charset='utf8mb4')
    try:
        with conn.cursor() as cursor:
            sql = f"""
                SELECT keyword, title, original_article_url
                FROM news_posts 
                WHERE DATE(crawled_at) = '{target_date}'
                ORDER BY copy_rate DESC LIMIT 100
            """
            cursor.execute(sql)
            results = cursor.fetchall()
            
            formatted_data = []
            for row in results:
                keyword = row[0]
                title = row[1]
                url = row[2] if row[2] else "URL ì—†ìŒ"
                formatted_data.append(f"- [{keyword}] {title} (URL: {url})")
            return formatted_data
    except Exception as e:
        log(f"âŒ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
        sys.exit(1)
    finally:
        conn.close()

def generate_summary(data_list):
    """ì œë¯¸ë‚˜ì´ë¥¼ ì´ìš©í•œ íŠ¸ë Œë“œ ìš”ì•½ ìƒì„±"""
    global current_key_index
    if not data_list:
        return "ë°ì´í„°ê°€ ì—†ì–´ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    context = "\n".join(data_list)
    
    # [í”„ë¡¬í”„íŠ¸ ìˆ˜ì •] ë§í¬ í˜•ì‹ì„ ë” ëª…í™•í•˜ê²Œ ì§€ì‹œ
    prompt = f"""
    ë„ˆëŠ” ë‰´ìŠ¤ ë°ì´í„° ë¶„ì„ê°€ì•¼. ì•„ë˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŠ¸ë Œë“œë¥¼ ìš”ì•½í•´ì¤˜.
    
    [ë°ì´í„°]
    {context}

    [í˜•ì‹]
    ğŸ’¡ ì˜¤ëŠ˜ì˜ í•µì‹¬ ì´ìŠˆ (5ê°€ì§€)
    1. (ì´ìŠˆ 1 - 2ì¤„ ìš”ì•½)
    2. (ì´ìŠˆ 2)
    3. (ì´ìŠˆ 3)
    4. (ì´ìŠˆ 4)
    5. (ì´ìŠˆ 5)

    ğŸ”¥ íŠ¸ë Œë“œ ë¶„ì„
    (ê´€ì‹¬ì‚¬ ë¶„ì„)

    ğŸ“° ì£¼ìš” ë‰´ìŠ¤ ë°”ë¡œê°€ê¸° (5ê°œ ì¶”ì²œ)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)
    - [ê¸°ì‚¬ ì œëª© ì „ì²´](ê¸°ì‚¬ URL)

    [ì£¼ì˜ì‚¬í•­]
    1. ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•(êµµê²Œ ë“±) ê¸ˆì§€. ë‹¨, ë§í¬ëŠ” ë°˜ë“œì‹œ [ì œëª©](ì£¼ì†Œ) í˜•ì‹ì„ ì§€í‚¬ ê²ƒ.
    2. ë§í¬ ìƒì„± ì‹œ [ì œëª©]ê³¼ (ì£¼ì†Œ) ì‚¬ì´ì— ë„ì–´ì“°ê¸°ë¥¼ í•˜ì§€ ë§ˆì‹œì˜¤.
    """
    
    max_retries = 3
    attempt = 0
    
    while attempt < max_retries:
        try:
            log(f"ğŸ¤– Gemini ìš”ì²­ ì‹œì‘ (Key #{current_key_index + 1}, ì‹œë„ {attempt + 1})...")
            response = model.generate_content(prompt)
            # ë§í¬ í¬ë§·([])ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë§ˆí¬ë‹¤ìš´ ì œê±°
            text = response.text.replace("**", "").replace("##", "").replace("###", "")
            return text
            
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "Quota" in error_msg or "ResourceExhausted" in error_msg:
                log(f"âš ï¸ í˜„ì¬ í‚¤(#{current_key_index + 1}) í•œë„ ì´ˆê³¼!")
                if len(API_KEYS) > 1:
                    current_key_index = (current_key_index + 1) % len(API_KEYS)
                    log(f"â™»ï¸ ë‹¤ìŒ í‚¤(#{current_key_index + 1})ë¡œ êµì²´í•©ë‹ˆë‹¤...")
                    configure_genai(current_key_index)
                    time.sleep(2)
                    continue 
                else:
                    wait_time = 60
                    log(f"â³ ì˜ˆë¹„ í‚¤ ì—†ìŒ. {wait_time}ì´ˆ ëŒ€ê¸°...")
                    time.sleep(wait_time)
                    attempt += 1
            else:
                log(f"âš ï¸ ì˜¤ë¥˜: {error_msg}")
                time.sleep(10)
                attempt += 1
            
    log("âŒ ì‹¤íŒ¨: ëª¨ë“  ì¬ì‹œë„ ì†Œì§„.")
    sys.exit(1)

# ğŸ‘‡ [í•µì‹¬ ê¸°ëŠ¥ ê°•í™”] í•˜ì´í¼ë§í¬ íŒŒì‹± ë¡œì§ ì—…ê·¸ë ˆì´ë“œ
def parse_markdown_to_notion_blocks(text):
    blocks = []
    lines = text.split('\n')
    
    # íŒ¨í„´ 1: ì •ìƒì ì¸ ë§ˆí¬ë‹¤ìš´ ë§í¬ [ì œëª©](ì£¼ì†Œ) - ë„ì–´ì“°ê¸° í—ˆìš©
    # \[([^\]]+)\] : ëŒ€ê´„í˜¸ ì•ˆì˜ ë‚´ìš© (ì œëª©)
    # \s* : ì¤‘ê°„ì— ê³µë°±ì´ ìˆì–´ë„ ë¨
    # \((https?://[^)]+)\) : ì†Œê´„í˜¸ ì•ˆì˜ httpë¡œ ì‹œì‘í•˜ëŠ” ì£¼ì†Œ
    link_pattern = re.compile(r'\[(.*?)\]\s*\((https?://.*?)\)')
    
    # íŒ¨í„´ 2: ê´„í˜¸ë§Œ ì³ì§„ URL (ë°±ì—…ìš©) -> "í…ìŠ¤íŠ¸ (URL)" í˜•íƒœ
    fallback_pattern = re.compile(r'(.*)\s*\((https?://.*?)\)')

    for line in lines:
        line = line.strip()
        if not line: continue
        
        # ë¸”ë¡ íƒ€ì… ê²°ì •
        if line.startswith("- "):
            block_type = "bulleted_list_item"
            content = line[2:]
        elif line[0].isdigit() and line[1:3] == ". ":
            block_type = "numbered_list_item"
            content = line[3:]
        elif line.startswith("ğŸ’¡") or line.startswith("ğŸ”¥") or line.startswith("ğŸ“°"):
            block_type = "heading_3"
            content = line
        else:
            block_type = "paragraph"
            content = line

        rich_text = []
        
        # 1. ë§ˆí¬ë‹¤ìš´ ë§í¬ íŒ¨í„´ ì‹œë„ [ì œëª©](ì£¼ì†Œ)
        match = link_pattern.search(content)
        
        # 2. ì‹¤íŒ¨ ì‹œ ë°±ì—… íŒ¨í„´ ì‹œë„ "ì œëª© (ì£¼ì†Œ)"
        if not match:
            fallback_match = fallback_pattern.search(content)
            # URL í˜•ì‹ì´ ë§ê³ , ì•ë¶€ë¶„(ì œëª©)ì´ ë„ˆë¬´ ì§§ì§€ ì•Šìœ¼ë©´ ë§í¬ë¡œ ì¸ì •
            if fallback_match:
                match = fallback_match

        if match:
            # ë§í¬ê°€ ìˆëŠ” ê²½ìš°
            # group(1): ì œëª©, group(2): URL
            title_text = match.group(1).replace("[", "").replace("]", "").strip() # ì œëª©ì— ë‚¨ì€ ëŒ€ê´„í˜¸ ì œê±°
            url_text = match.group(2).strip()
            
            # ë§í¬ ì•ë¶€ë¶„ í…ìŠ¤íŠ¸ (ìˆë‹¤ë©´)
            pre_text = content[:match.start()].strip()
            if pre_text:
                rich_text.append({"type": "text", "text": {"content": pre_text + " "}})
                
            # ë§í¬ ë¶€ë¶„ (í´ë¦­ ê°€ëŠ¥í•˜ê²Œ)
            rich_text.append({
                "type": "text",
                "text": {
                    "content": title_text,
                    "link": {"url": url_text} # ğŸ”— í•˜ì´í¼ë§í¬ ì ìš©
                }
            })
        else:
            # ë§í¬ê°€ ì—†ëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸
            rich_text.append({"type": "text", "text": {"content": content}})

        blocks.append({
            "object": "block",
            "type": block_type,
            block_type: {
                "rich_text": rich_text
            }
        })
        
    return blocks

def create_summary_page_in_notion(summary_text, target_date):
    headers = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }
    
    # íŒŒì‹±ëœ ë¸”ë¡ ìƒì„±
    content_blocks = parse_markdown_to_notion_blocks(summary_text)

    payload = {
        "parent": {"page_id": NOTION_PAGE_ID}, 
        "properties": {
            "title": { 
                "title": [
                    {"text": {"content": f"ğŸ¤– {target_date} AI ìš”ì•½ ë¦¬í¬íŠ¸"}}
                ]
            }
        },
        "children": [
            {
                "object": "block",
                "type": "callout",
                "callout": {
                    "rich_text": [{"type": "text", "text": {"content": "Gemini 2.5 Flash ë‰´ìŠ¤ ìš”ì•½"}}],
                    "icon": {"emoji": "ğŸ“°"},
                    "color": "gray_background"
                }
            },
            {
                "object": "block",
                "type": "divider",
                "divider": {}
            }
        ] + content_blocks
    }
    
    url = "https://api.notion.com/v1/pages"
    
    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        log(f"âœ… ë…¸ì…˜ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {target_date}")
        
    except requests.exceptions.HTTPError as err:
        log(f"âŒ ë…¸ì…˜ ìš”ì²­ ì‹¤íŒ¨: {err}")
        log(f"ì‘ë‹µ ë‚´ìš©: {response.text}")
        sys.exit(1)

def run_gemini_pipeline(target_date):
    news_data = get_yesterday_data(target_date)
    log(f"ë°ì´í„° {len(news_data)}ê±´ ì¡°íšŒë¨.")
    
    if not news_data:
        log("ë°ì´í„°ê°€ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    summary = generate_summary(news_data)
    log("Gemini ìš”ì•½ ì™„ë£Œ.")
    
    create_summary_page_in_notion(summary, target_date)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--date", help="ë°ì´í„° ì¡°íšŒ ëŒ€ìƒ ë‚ ì§œ (YYYY-MM-DD)")
    args = parser.parse_args()

    if args.date:
        run_gemini_pipeline(args.date)
    else:
        log("âš ï¸ ë‚ ì§œ(--date) íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        sys.exit(1)